{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSG8T308a-_u"
      },
      "source": [
        "# Breast Cancer Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjGwUnyGSwK7"
      },
      "source": [
        "Over the past decades, machine learning techniques have been widely used in intelligent health systems, particularly for breast cancer diagnosis and prognosis. In this article, I will walk you through how to create a breast cancer detection model using machine learning and the Python programming language.\n",
        "\n",
        "Breast cancer is one of the most common cancers in women globally, accounting for the majority of new cancer cases and cancer-related deaths according to global statistics, making it a major public health problem in the world. todayâ€™s society.\n",
        "\n",
        "Early diagnosis of breast cancer can dramatically improve prognosis and chances of survival, as it can promote timely clinical treatment of patients. More precise classification of benign tumours can prevent patients from undergoing unnecessary treatments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpkpIEdwS2RJ"
      },
      "source": [
        "Dataset :- https://www.kaggle.com/uciml/breast-cancer-wisconsin-data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcD_Od_Ev_dL"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import numpy as np #2 perform mathematical operations on arrays\n",
        "import pandas as pd #for data analysis\n",
        "import sklearn.datasets #embeds sm small toy datasets \n",
        "import seaborn as sns #statistical graphics\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression #predict the propability of a categorical dependent variable\n",
        "from sklearn.model_selection import train_test_split #measure the accuracy of the model \n",
        "from sklearn.metrics import accuracy_score #measure model performance\n",
        "from sklearn.model_selection import cross_val_score #statistical method used to estimate the performance (or accuracy) of machine learning models\n",
        "from sklearn.preprocessing import StandardScaler #resize the distribution of values\n",
        "from sklearn.neighbors import KNeighborsClassifier #represents the K nearest neighbors\n",
        "from sklearn.svm import SVC #fit the data u provide, returning a \"best fit\" hyperplane that devides/categorizes ur data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9DYHgCVwIbz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd02157d-fc77-40b2-9124-8001d2278e17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
            "        1.189e-01],\n",
            "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
            "        8.902e-02],\n",
            "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
            "        8.758e-02],\n",
            "       ...,\n",
            "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
            "        7.820e-02],\n",
            "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
            "        1.240e-01],\n",
            "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
            "        7.039e-02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
            "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
            "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
            "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
            "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
            "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
            "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
            "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
            "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
            "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
            "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
            "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
            "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
            "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), 'frame': None, 'target_names': array(['malignant', 'benign'], dtype='<U9'), 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.', 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
            "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
            "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
            "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
            "       'smoothness error', 'compactness error', 'concavity error',\n",
            "       'concave points error', 'symmetry error',\n",
            "       'fractal dimension error', 'worst radius', 'worst texture',\n",
            "       'worst perimeter', 'worst area', 'worst smoothness',\n",
            "       'worst compactness', 'worst concavity', 'worst concave points',\n",
            "       'worst symmetry', 'worst fractal dimension'], dtype='<U23'), 'filename': 'breast_cancer.csv', 'data_module': 'sklearn.datasets.data'}\n"
          ]
        }
      ],
      "source": [
        "#getting the dataset frm sklearn\n",
        "breast_cancer = sklearn.datasets.load_breast_cancer()\n",
        "\n",
        "#printing the dataset\n",
        "print(breast_cancer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgcuLbiJxOHR"
      },
      "outputs": [],
      "source": [
        "#assigning data as x\n",
        "x = breast_cancer.data \n",
        "\n",
        "#assigning labels as y\n",
        "y = breast_cancer.target "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsFe55bVxXEZ",
        "outputId": "5af60e90-7845-4e4a-a142-54952120fb2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
            " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
            " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
            " ...\n",
            " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
            " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
            " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n",
            "--------------------------------------------------------------------------------------------------\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
            " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
            " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
            " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
            " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
            " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
            " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n"
          ]
        }
      ],
      "source": [
        "print(x) #printing the data\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(y) #printing the labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsQmZrAi2wvK"
      },
      "source": [
        "### Printing names of features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGwi7P2gHwMT",
        "outputId": "26b5da9c-89e4-4b55-c6de-b652b3abda99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
              "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
              "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
              "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
              "       'smoothness error', 'compactness error', 'concavity error',\n",
              "       'concave points error', 'symmetry error',\n",
              "       'fractal dimension error', 'worst radius', 'worst texture',\n",
              "       'worst perimeter', 'worst area', 'worst smoothness',\n",
              "       'worst compactness', 'worst concavity', 'worst concave points',\n",
              "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#printing the names of features\n",
        "breast_cancer.feature_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re_SKySK2wvR"
      },
      "source": [
        "### Checking Dimensions of x and y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he2YLzzRxf_J",
        "outputId": "5a28b3dc-6765-430e-b647-0c71f9f15492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569, 30) (569,)\n"
          ]
        }
      ],
      "source": [
        "#printing the sahpe of data & labels\n",
        "print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEwjIKoD2wvZ"
      },
      "source": [
        "### Storing data as pandas dataframe to perform further operations "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCV8SYEjxouh"
      },
      "outputs": [],
      "source": [
        "#loading the data 2 pandas dataframe \n",
        "#by creating variable named \"data\"\n",
        "#wyt columns of features names\n",
        "data = pd.DataFrame(breast_cancer.data, columns = breast_cancer.feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBb39RgNx6Ja"
      },
      "outputs": [],
      "source": [
        "#making a class called \"class\"\n",
        "#class represents labels which is 0/1\n",
        "data['class'] = breast_cancer.target "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v_-Z0Kf2wvf"
      },
      "source": [
        "### Printing the head of the dataset to have a look at the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "mw3Jb_p2x8mp",
        "outputId": "b106bf26-9ca6-4b1a-a94e-1063be4284dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d7c6225c-5bc6-47c6-b8e5-19178996b0f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>12.45</td>\n",
              "      <td>15.70</td>\n",
              "      <td>82.57</td>\n",
              "      <td>477.1</td>\n",
              "      <td>0.12780</td>\n",
              "      <td>0.17000</td>\n",
              "      <td>0.15780</td>\n",
              "      <td>0.08089</td>\n",
              "      <td>0.2087</td>\n",
              "      <td>0.07613</td>\n",
              "      <td>0.3345</td>\n",
              "      <td>0.8902</td>\n",
              "      <td>2.217</td>\n",
              "      <td>27.19</td>\n",
              "      <td>0.007510</td>\n",
              "      <td>0.03345</td>\n",
              "      <td>0.03672</td>\n",
              "      <td>0.01137</td>\n",
              "      <td>0.02165</td>\n",
              "      <td>0.005082</td>\n",
              "      <td>15.47</td>\n",
              "      <td>23.75</td>\n",
              "      <td>103.40</td>\n",
              "      <td>741.6</td>\n",
              "      <td>0.1791</td>\n",
              "      <td>0.5249</td>\n",
              "      <td>0.5355</td>\n",
              "      <td>0.1741</td>\n",
              "      <td>0.3985</td>\n",
              "      <td>0.12440</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>18.25</td>\n",
              "      <td>19.98</td>\n",
              "      <td>119.60</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>0.09463</td>\n",
              "      <td>0.10900</td>\n",
              "      <td>0.11270</td>\n",
              "      <td>0.07400</td>\n",
              "      <td>0.1794</td>\n",
              "      <td>0.05742</td>\n",
              "      <td>0.4467</td>\n",
              "      <td>0.7732</td>\n",
              "      <td>3.180</td>\n",
              "      <td>53.91</td>\n",
              "      <td>0.004314</td>\n",
              "      <td>0.01382</td>\n",
              "      <td>0.02254</td>\n",
              "      <td>0.01039</td>\n",
              "      <td>0.01369</td>\n",
              "      <td>0.002179</td>\n",
              "      <td>22.88</td>\n",
              "      <td>27.66</td>\n",
              "      <td>153.20</td>\n",
              "      <td>1606.0</td>\n",
              "      <td>0.1442</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.3784</td>\n",
              "      <td>0.1932</td>\n",
              "      <td>0.3063</td>\n",
              "      <td>0.08368</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>13.71</td>\n",
              "      <td>20.83</td>\n",
              "      <td>90.20</td>\n",
              "      <td>577.9</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0.16450</td>\n",
              "      <td>0.09366</td>\n",
              "      <td>0.05985</td>\n",
              "      <td>0.2196</td>\n",
              "      <td>0.07451</td>\n",
              "      <td>0.5835</td>\n",
              "      <td>1.3770</td>\n",
              "      <td>3.856</td>\n",
              "      <td>50.96</td>\n",
              "      <td>0.008805</td>\n",
              "      <td>0.03029</td>\n",
              "      <td>0.02488</td>\n",
              "      <td>0.01448</td>\n",
              "      <td>0.01486</td>\n",
              "      <td>0.005412</td>\n",
              "      <td>17.06</td>\n",
              "      <td>28.14</td>\n",
              "      <td>110.60</td>\n",
              "      <td>897.0</td>\n",
              "      <td>0.1654</td>\n",
              "      <td>0.3682</td>\n",
              "      <td>0.2678</td>\n",
              "      <td>0.1556</td>\n",
              "      <td>0.3196</td>\n",
              "      <td>0.11510</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>13.00</td>\n",
              "      <td>21.82</td>\n",
              "      <td>87.50</td>\n",
              "      <td>519.8</td>\n",
              "      <td>0.12730</td>\n",
              "      <td>0.19320</td>\n",
              "      <td>0.18590</td>\n",
              "      <td>0.09353</td>\n",
              "      <td>0.2350</td>\n",
              "      <td>0.07389</td>\n",
              "      <td>0.3063</td>\n",
              "      <td>1.0020</td>\n",
              "      <td>2.406</td>\n",
              "      <td>24.32</td>\n",
              "      <td>0.005731</td>\n",
              "      <td>0.03502</td>\n",
              "      <td>0.03553</td>\n",
              "      <td>0.01226</td>\n",
              "      <td>0.02143</td>\n",
              "      <td>0.003749</td>\n",
              "      <td>15.49</td>\n",
              "      <td>30.73</td>\n",
              "      <td>106.20</td>\n",
              "      <td>739.3</td>\n",
              "      <td>0.1703</td>\n",
              "      <td>0.5401</td>\n",
              "      <td>0.5390</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.4378</td>\n",
              "      <td>0.10720</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>12.46</td>\n",
              "      <td>24.04</td>\n",
              "      <td>83.97</td>\n",
              "      <td>475.9</td>\n",
              "      <td>0.11860</td>\n",
              "      <td>0.23960</td>\n",
              "      <td>0.22730</td>\n",
              "      <td>0.08543</td>\n",
              "      <td>0.2030</td>\n",
              "      <td>0.08243</td>\n",
              "      <td>0.2976</td>\n",
              "      <td>1.5990</td>\n",
              "      <td>2.039</td>\n",
              "      <td>23.94</td>\n",
              "      <td>0.007149</td>\n",
              "      <td>0.07217</td>\n",
              "      <td>0.07743</td>\n",
              "      <td>0.01432</td>\n",
              "      <td>0.01789</td>\n",
              "      <td>0.010080</td>\n",
              "      <td>15.09</td>\n",
              "      <td>40.68</td>\n",
              "      <td>97.65</td>\n",
              "      <td>711.4</td>\n",
              "      <td>0.1853</td>\n",
              "      <td>1.0580</td>\n",
              "      <td>1.1050</td>\n",
              "      <td>0.2210</td>\n",
              "      <td>0.4366</td>\n",
              "      <td>0.20750</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7c6225c-5bc6-47c6-b8e5-19178996b0f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d7c6225c-5bc6-47c6-b8e5-19178996b0f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d7c6225c-5bc6-47c6-b8e5-19178996b0f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   mean radius  mean texture  ...  worst fractal dimension  class\n",
              "0        17.99         10.38  ...                  0.11890      0\n",
              "1        20.57         17.77  ...                  0.08902      0\n",
              "2        19.69         21.25  ...                  0.08758      0\n",
              "3        11.42         20.38  ...                  0.17300      0\n",
              "4        20.29         14.34  ...                  0.07678      0\n",
              "5        12.45         15.70  ...                  0.12440      0\n",
              "6        18.25         19.98  ...                  0.08368      0\n",
              "7        13.71         20.83  ...                  0.11510      0\n",
              "8        13.00         21.82  ...                  0.10720      0\n",
              "9        12.46         24.04  ...                  0.20750      0\n",
              "\n",
              "[10 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#printing the Top 10 sample values in the dataframe\n",
        "data.head(10) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfdZ78gi2wvl"
      },
      "source": [
        "### Having a look at details of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "u6ctixeazqZC",
        "outputId": "2840083a-72db-4fad-d286-529b5fb4ed76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-96824a6d-e921-4a61-b2b5-73469f8a528d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>0.405172</td>\n",
              "      <td>1.216853</td>\n",
              "      <td>2.866059</td>\n",
              "      <td>40.337079</td>\n",
              "      <td>0.007041</td>\n",
              "      <td>0.025478</td>\n",
              "      <td>0.031894</td>\n",
              "      <td>0.011796</td>\n",
              "      <td>0.020542</td>\n",
              "      <td>0.003795</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "      <td>0.627417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.277313</td>\n",
              "      <td>0.551648</td>\n",
              "      <td>2.021855</td>\n",
              "      <td>45.491006</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>0.017908</td>\n",
              "      <td>0.030186</td>\n",
              "      <td>0.006170</td>\n",
              "      <td>0.008266</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "      <td>0.483918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>0.111500</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.757000</td>\n",
              "      <td>6.802000</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007882</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>0.232400</td>\n",
              "      <td>0.833900</td>\n",
              "      <td>1.606000</td>\n",
              "      <td>17.850000</td>\n",
              "      <td>0.005169</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.015090</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.015160</td>\n",
              "      <td>0.002248</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.324200</td>\n",
              "      <td>1.108000</td>\n",
              "      <td>2.287000</td>\n",
              "      <td>24.530000</td>\n",
              "      <td>0.006380</td>\n",
              "      <td>0.020450</td>\n",
              "      <td>0.025890</td>\n",
              "      <td>0.010930</td>\n",
              "      <td>0.018730</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>0.478900</td>\n",
              "      <td>1.474000</td>\n",
              "      <td>3.357000</td>\n",
              "      <td>45.190000</td>\n",
              "      <td>0.008146</td>\n",
              "      <td>0.032450</td>\n",
              "      <td>0.042050</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.023480</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>2.873000</td>\n",
              "      <td>4.885000</td>\n",
              "      <td>21.980000</td>\n",
              "      <td>542.200000</td>\n",
              "      <td>0.031130</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>0.052790</td>\n",
              "      <td>0.078950</td>\n",
              "      <td>0.029840</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96824a6d-e921-4a61-b2b5-73469f8a528d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-96824a6d-e921-4a61-b2b5-73469f8a528d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-96824a6d-e921-4a61-b2b5-73469f8a528d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       mean radius  mean texture  ...  worst fractal dimension       class\n",
              "count   569.000000    569.000000  ...               569.000000  569.000000\n",
              "mean     14.127292     19.289649  ...                 0.083946    0.627417\n",
              "std       3.524049      4.301036  ...                 0.018061    0.483918\n",
              "min       6.981000      9.710000  ...                 0.055040    0.000000\n",
              "25%      11.700000     16.170000  ...                 0.071460    0.000000\n",
              "50%      13.370000     18.840000  ...                 0.080040    1.000000\n",
              "75%      15.780000     21.800000  ...                 0.092080    1.000000\n",
              "max      28.110000     39.280000  ...                 0.207500    1.000000\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#now lets c statistical values of data\n",
        "#Basic Descriptive statistics on the data\n",
        "data.describe(include = \"all\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOYQ0YdS2wv5"
      },
      "source": [
        "### Counterplot\n",
        "Showing the total count of malignant and benign tumor patients in counterplot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "2IO60crBI9dm",
        "outputId": "aa47be42-826a-4a73-b8d4-0d75bfa26925"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f42d74dad90>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#counts no of observations per category\n",
        "sns.countplot(data['class'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evtSd2rV2wwQ"
      },
      "source": [
        "#### Checking Number of benign and malignant cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WajP-t00Knp",
        "outputId": "ab54f33a-d14f-4f35-ae99-66ad445cddc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    357\n",
            "0    212\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#v can c how many examples r there for class 1 & 0\n",
        "print(data['class'].value_counts()) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeKRtr0j0QTB",
        "outputId": "08784fce-d764-4aba-b06d-5647322e070f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['malignant' 'benign']\n"
          ]
        }
      ],
      "source": [
        "#lets c wht 0 & 1 r\n",
        "print(breast_cancer.target_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "10jwUfon0Y9h",
        "outputId": "f1634f18-0f71-47a0-a9d4-a4f2ea302c8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7105ef31-ab6d-4079-a253-1f18b6428dd9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.462830</td>\n",
              "      <td>21.604906</td>\n",
              "      <td>115.365377</td>\n",
              "      <td>978.376415</td>\n",
              "      <td>0.102898</td>\n",
              "      <td>0.145188</td>\n",
              "      <td>0.160775</td>\n",
              "      <td>0.087990</td>\n",
              "      <td>0.192909</td>\n",
              "      <td>0.062680</td>\n",
              "      <td>0.609083</td>\n",
              "      <td>1.210915</td>\n",
              "      <td>4.323929</td>\n",
              "      <td>72.672406</td>\n",
              "      <td>0.006780</td>\n",
              "      <td>0.032281</td>\n",
              "      <td>0.041824</td>\n",
              "      <td>0.015060</td>\n",
              "      <td>0.020472</td>\n",
              "      <td>0.004062</td>\n",
              "      <td>21.134811</td>\n",
              "      <td>29.318208</td>\n",
              "      <td>141.370330</td>\n",
              "      <td>1422.286321</td>\n",
              "      <td>0.144845</td>\n",
              "      <td>0.374824</td>\n",
              "      <td>0.450606</td>\n",
              "      <td>0.182237</td>\n",
              "      <td>0.323468</td>\n",
              "      <td>0.091530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12.146524</td>\n",
              "      <td>17.914762</td>\n",
              "      <td>78.075406</td>\n",
              "      <td>462.790196</td>\n",
              "      <td>0.092478</td>\n",
              "      <td>0.080085</td>\n",
              "      <td>0.046058</td>\n",
              "      <td>0.025717</td>\n",
              "      <td>0.174186</td>\n",
              "      <td>0.062867</td>\n",
              "      <td>0.284082</td>\n",
              "      <td>1.220380</td>\n",
              "      <td>2.000321</td>\n",
              "      <td>21.135148</td>\n",
              "      <td>0.007196</td>\n",
              "      <td>0.021438</td>\n",
              "      <td>0.025997</td>\n",
              "      <td>0.009858</td>\n",
              "      <td>0.020584</td>\n",
              "      <td>0.003636</td>\n",
              "      <td>13.379801</td>\n",
              "      <td>23.515070</td>\n",
              "      <td>87.005938</td>\n",
              "      <td>558.899440</td>\n",
              "      <td>0.124959</td>\n",
              "      <td>0.182673</td>\n",
              "      <td>0.166238</td>\n",
              "      <td>0.074444</td>\n",
              "      <td>0.270246</td>\n",
              "      <td>0.079442</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7105ef31-ab6d-4079-a253-1f18b6428dd9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7105ef31-ab6d-4079-a253-1f18b6428dd9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7105ef31-ab6d-4079-a253-1f18b6428dd9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
              "class                             ...                                         \n",
              "0        17.462830     21.604906  ...        0.323468                 0.091530\n",
              "1        12.146524     17.914762  ...        0.270246                 0.079442\n",
              "\n",
              "[2 rows x 30 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#v r just finding the mean values of malignant & benign\n",
        "#in malignant stage cancer the size of the breast is big compared 2 benign stage cancer(by the values of the mean)\n",
        "#that difference is very much imp for this classification\n",
        "data.groupby('class').mean() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ_0JuisfRQ-"
      },
      "source": [
        "0 - Malignant\n",
        "\n",
        "1 - Benign"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MKrr9LW2wwf"
      },
      "source": [
        "#### Dividing data into train and test data using sklearn's train_test_split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kHSJel9KvyK"
      },
      "outputs": [],
      "source": [
        "#spliting the dataset in2 Training & Testing \n",
        "\n",
        "#x_train --> Training Data // x_test --> Testing Data\n",
        "#y_train --> Label for training data // y_test --> Label for testing data\n",
        "#Labels --> 0 & 1 \n",
        "\n",
        "#spliting the dataset based on test size v needed\n",
        "#test size --> 2 specify the percentage of test data needed ==> 0.1 ==> 10%\n",
        "\n",
        "#random state --> specific split of data each value of random_state splits the data differently, v can put any state v want\n",
        "#v need 2 specify the same random_state everytym if v want 2 split the data the same way everytym\n",
        "\n",
        "#stratifying it based on the y, so that the data is split in the crt way\n",
        "#stratify --> for crt distribution of data as of the original data(2 split the data correctly as of the original data)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state = 42, stratify = y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjThaKHV1_V8",
        "outputId": "c41ebc44-08df-4938-c63b-2a095425f698"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569,) (512,) (57,)\n"
          ]
        }
      ],
      "source": [
        "#lets c how many examples r there for each cases\n",
        "#checking dimension of target\n",
        "print(y.shape, y_train.shape, y_test.shape) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egDoDuMRK2IB",
        "outputId": "9355f179-eb5c-4e28-c12b-c6648f2ff102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569, 30) (512, 30) (57, 30)\n"
          ]
        }
      ],
      "source": [
        "#checking dimension of features\n",
        "print(x.shape, x_train.shape, x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftyD3HAtLb-D",
        "outputId": "e1be8e1d-18e9-4379-c59d-86ad94f5b3e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6274165202108963 0.626953125 0.631578947368421\n"
          ]
        }
      ],
      "source": [
        "#checking mean of target\n",
        "#mean value should b same for original data, train data & test data\n",
        "print(y.mean(), y_train.mean(), y_test.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfu56AsMLhAi",
        "outputId": "2d804d51-64da-4e59-e45e-6b9bd5e00787"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61.890712339519624 61.643943173802086 64.10730554736843\n"
          ]
        }
      ],
      "source": [
        "#checking mean of features\n",
        "#the mean value of x, x_train & x_test will not b same\n",
        "#coz there r 30 features & differs for each feature\n",
        "print(x.mean(), x_train.mean(), x_test.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObkYPkOF4yPA",
        "outputId": "9e6c5978-f256-435c-ec6b-7929332d3a72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.499e+01 2.211e+01 9.753e+01 ... 1.308e-01 3.163e-01 9.251e-02]\n",
            " [1.989e+01 2.026e+01 1.305e+02 ... 1.613e-01 2.549e-01 9.136e-02]\n",
            " [1.048e+01 1.986e+01 6.672e+01 ... 6.736e-02 2.883e-01 7.748e-02]\n",
            " ...\n",
            " [1.114e+01 1.407e+01 7.124e+01 ... 3.922e-02 2.576e-01 7.018e-02]\n",
            " [9.876e+00 1.940e+01 6.395e+01 ... 9.749e-02 2.622e-01 8.490e-02]\n",
            " [1.065e+01 2.522e+01 6.801e+01 ... 6.136e-02 3.409e-01 8.147e-02]]\n"
          ]
        }
      ],
      "source": [
        "#printing the substrain\n",
        "print(x_train) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7tDfIDI2ww1"
      },
      "source": [
        "## Our data is ready to be applied a machine learning algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0r7oQcI2ww2"
      },
      "source": [
        "# ***Logistic Regression***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TKkb9-U2ww3"
      },
      "source": [
        "### Implementing Logistic Regression without scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "826anBmS5FHh",
        "outputId": "2d1d4c31-bc7e-4e84-bc99-6f5597e9a788"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ],
      "source": [
        "#loading the logistic regression 2 the variable \"clf\"\n",
        "#training the model on training data\n",
        "#v r fitting the data x_train 2 the clf which is the logistic regression model, so the model is trained with the data\n",
        "clf = LogisticRegression().fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGLP4z2KB2lv"
      },
      "source": [
        "## **Evaluation of the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cF1sRkKh2ww6"
      },
      "source": [
        "## Predicting seen data with our Logistic Regression ML model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoXdtuq6A3xy",
        "outputId": "c9282e46-2dd0-4bc0-d385-bf2315dcce40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
              "       0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
              "       0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
              "       1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
              "       0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
              "       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
              "       1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
              "       0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
              "       1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
              "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "#prediction on train_data\n",
        "train_pred = clf.predict(x_train)\n",
        "train_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQNTw49o2ww_"
      },
      "source": [
        "## Predicting unseen data with our Logistic Regression ML model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxpsJrMABF0y",
        "outputId": "75ee78a9-531e-46d1-9ad6-0559f3396b04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
              "       1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "#prediction on test_data\n",
        "test_pred = clf.predict(x_test)\n",
        "test_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeMlceJG2wxD"
      },
      "source": [
        "## Checking Accuracy of Logistic Regression ML model with training data and testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1Emjb0XBOSq"
      },
      "outputs": [],
      "source": [
        "#v r finding the accuracy_score on the training data 2 check how the model performs on traing data \n",
        "train_accuracy = accuracy_score(y_train, train_pred)\n",
        "\n",
        "#v r finding the accuracy_score on the testing data 2 check how the model performs on testing data\n",
        "test_accuracy = accuracy_score(y_test, test_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOlOtKa7BPcK",
        "outputId": "0fadeae8-52a0-4b7a-a617-c696de6b3546"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy:  0.951171875\n",
            "Testing accuracy:  0.9298245614035088\n"
          ]
        }
      ],
      "source": [
        "#print the accuracy_score on training data\n",
        "print(\"Training accuracy: \", train_accuracy)\n",
        "\n",
        "#print the accuracy_score on testing data\n",
        "print(\"Testing accuracy: \", test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQexBkcF2wxN"
      },
      "source": [
        "## Logistic Regression ML model Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvwDYh3pC0mC",
        "outputId": "c09fb342-a350-4980-d4e5-7da37244d0d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.951171875"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "#mean accuracy (accuracy score)\n",
        "#measuring the accuracy of the model against the training data \n",
        "clf.score(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBB8BZCuC8RS",
        "outputId": "d4053490-8fbd-46d0-b96b-483a5907581f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9298245614035088"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "#mean accuracy (accuracy score)\n",
        "#measuring the accuracy of the model against the test data \n",
        "clf.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSnVinOyQR7P"
      },
      "source": [
        "Lets Cross Validate and Check how the model performs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-aJ_ogDDShT",
        "outputId": "32bea58c-5280-4fcc-8863-057f0afb2553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.93859649 0.93859649 0.95614035 0.94736842 0.95575221]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ],
      "source": [
        "#cross validation\n",
        "#it is used to protect against overfitting in a predictive model, \n",
        "#particularly in a case where the amount of data may be limited. In cross-validation, \n",
        "#you make a fixed number of folds (or partitions) of the data, run the analysis on each fold, and then average the overall error estimate.\n",
        "#cv = 5 ==> partition the data in2 4 Training & 1 Testing Data parts\n",
        "print(cross_val_score(clf, x, y, cv = 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAFwXF7y5nO7"
      },
      "source": [
        "### Logistic Regression Model Has Performed Wonderfully After Feature Selection\n",
        "#### Let's look a few more models to see how they perform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si0y2pPn2wxf"
      },
      "source": [
        "# ***SVM***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bpfEAGQ2wxf"
      },
      "source": [
        "### Implementing Support Vector Machine Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0h18tlZD9Vz"
      },
      "outputs": [],
      "source": [
        "#loading the SVM 2 the variable \"clf_svm\"\n",
        "#training the SVM Model with Training Data\n",
        "#v r fitting the data x_train, y_train 2 the model which is the svm model, so the model is trained with the data\n",
        "#rbf(Rdial Basis Function) Kernel is so popular coz of its similarity 2 KNN Algo\n",
        "#rbf kernel SVM just needs 2 store the support vectors during tarining & not the entire dataset\n",
        "clf_svm = SVC(kernel = 'rbf').fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlqrM6UE2wxl"
      },
      "source": [
        "### Predicting seen data with our SVM ML model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s6E-CwtESzE",
        "outputId": "e8d7c897-3ed3-41bd-e129-4f19a762b8d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
              "       0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
              "       1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
              "       0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
              "       0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "#prediction on train_data\n",
        "svmtrain_pred = clf_svm.predict(x_train)\n",
        "svmtrain_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY732CEY2wxq"
      },
      "source": [
        "### Predicting unseen data with our SVM ML model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4oz78AXEX_M",
        "outputId": "c4c31d2f-01d7-42a4-cfe6-f77bab927481"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "#prediction on test_data\n",
        "svmtest_pred = clf_svm.predict(x_test)\n",
        "svmtest_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRc0yvii2wxv"
      },
      "source": [
        "## Checking Accuracy of SVM ML model with training data and testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjH2VZIPEd87"
      },
      "outputs": [],
      "source": [
        "#v r finding the accuracy_score on the training data 2 check how the model performs on traing data \n",
        "svmtrain_accuracy = accuracy_score(y_train, svmtrain_pred)\n",
        "\n",
        "#v r finding the accuracy_score on the testing data 2 check how the model performs on testing data \n",
        "svmtest_accuracy = accuracy_score(y_test, svmtest_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBvyd1hSEgDb",
        "outputId": "67208139-a3ea-4f51-aef0-d871618c4ae5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy:  0.91796875\n",
            "Testing accuracy:  0.9298245614035088\n"
          ]
        }
      ],
      "source": [
        "#print the accuracy_score on training data\n",
        "print(\"Training accuracy: \", svmtrain_accuracy)\n",
        "\n",
        "#print the accuracy_score on testing data\n",
        "print(\"Testing accuracy: \", svmtest_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnhSDa_F2wx5"
      },
      "source": [
        "## SVM ML MODEL SCORE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3AVak28EkTb",
        "outputId": "268bfe93-f78b-45a0-903d-b051cc34e1f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.91796875"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "#mean accuracy (accuracy score)\n",
        "#measuring the accuracy of the model against the training data \n",
        "clf_svm.score(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miwjGR_2Em0K",
        "outputId": "c9d9fc87-2113-44a2-cca6-370540e04502"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9298245614035088"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "#mean accuracy (accuracy score)\n",
        "#measuring the accuracy of the model against the test data \n",
        "clf_svm.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3asXRX5EnnV",
        "outputId": "0706e968-7879-49d7-fd4c-1c93759301c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.85087719 0.89473684 0.92982456 0.94736842 0.9380531 ]\n"
          ]
        }
      ],
      "source": [
        "#cross validation\n",
        "#it is used to protect against overfitting in a predictive model, \n",
        "#particularly in a case where the amount of data may be limited. In cross-validation, \n",
        "#you make a fixed number of folds (or partitions) of the data, run the analysis on each fold, and then average the overall error estimate.\n",
        "#cv = 5 ==> partition the data in2 4 Training & 1 Testing Data parts\n",
        "print(cross_val_score(clf_svm, x, y, cv = 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk1nuOaz2wyD"
      },
      "source": [
        "# ***KNN***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HxggxwJXHRE"
      },
      "source": [
        "### Implementing K Nearest neighbors classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E22-xluuExO8"
      },
      "outputs": [],
      "source": [
        "#loading the KNN 2 the variable \"clf_knn\"\n",
        "#training the KNN Model with Training Data\n",
        "#v r fitting the data x_train, y_train 2 the model which is the knn model, so the model is trained with the data\n",
        "#v r assuming K(n_neighbors) = 3 ==> it would find three nearest data points\n",
        "clf_knn = KNeighborsClassifier(n_neighbors = 3).fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lJsuWpbWuEO"
      },
      "source": [
        "### Predicting seen data with our KNN ML model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pFdr83HEzYM",
        "outputId": "e89c90f9-3f58-4139-d6b0-bc00c80df2bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
              "       0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
              "       0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "       1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
              "       0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
              "       1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
              "       0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
              "       1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "#prediction on train_data\n",
        "trainknn_pred = clf_knn.predict(x_train)\n",
        "trainknn_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz-dU7lnXAbf"
      },
      "source": [
        "### Predicting unseen data with our KNN ML model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLIyLGCmE13a",
        "outputId": "65ab6999-d492-4656-d182-f95cfdb3ab01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "#Predicting Unseen Data\n",
        "testknn_pred = clf_knn.predict(x_test)\n",
        "testknn_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FY1goWBX2wyR"
      },
      "source": [
        "## Checking Accuracy of KNN ML model with training data and testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2SqO-HuFD40"
      },
      "outputs": [],
      "source": [
        "#v r finding the accuracy_score on the training data 2 check how the model performs on traing data\n",
        "trainknn_accuracy = accuracy_score(y_train, trainknn_pred)\n",
        "\n",
        "#v r finding the accuracy_score on the testing data 2 check how the model performs on testing data\n",
        "testknn_accuracy = accuracy_score(y_test, testknn_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvY0MLtUFFzF",
        "outputId": "ebf5528f-cb2a-4769-80bc-f40572ca9305"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy:  0.955078125\n",
            "Testing accuracy:  0.9122807017543859\n"
          ]
        }
      ],
      "source": [
        "#print the accuracy_score on training data\n",
        "print(\"Training accuracy: \", trainknn_accuracy)\n",
        "\n",
        "#print the accuracy_score on testing data\n",
        "print(\"Testing accuracy: \", testknn_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV-PAoc72wyX"
      },
      "source": [
        "## KNN ML MODEL SCORE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OL5attJZFKVT",
        "outputId": "549b6809-02a2-4945-9ec7-e68d64504173"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.955078125"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "#mean accuracy (accuracy score)\n",
        "#measuring the accuracy of the model against the training data \n",
        "clf_knn.score(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsEeOXW_FOyN",
        "outputId": "25d13f48-1187-4bc1-86fe-967efe4cfd73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9122807017543859"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "#mean accuracy (accuracy score)\n",
        "#measuring the accuracy of the model against the test data \n",
        "clf_knn.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95l-InpFFQeC",
        "outputId": "63982692-8be8-4bb4-aa81-cb76f7be8191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.87719298 0.92105263 0.94736842 0.93859649 0.91150442]\n"
          ]
        }
      ],
      "source": [
        "#cross validation\n",
        "#it is used to protect against overfitting in a predictive model, \n",
        "#particularly in a case where the amount of data may be limited. In cross-validation, \n",
        "#you make a fixed number of folds (or partitions) of the data, run the analysis on each fold, and then average the overall error estimate.\n",
        "#cv = 5 ==> partition the data in2 4 Training & 1 Testing Data parts\n",
        "print(cross_val_score(clf_knn, x, y, cv = 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K2jbjxZ2wyg"
      },
      "source": [
        "# Comparing Out of Sample Accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bbcHemsFbF5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e45c911e-8faa-43da-e3d9-47dc4bc17f89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'KNN': 0.9122807017543859,\n",
              " 'LogisticRegression': 0.9298245614035088,\n",
              " 'SVM': 0.9298245614035088}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "#create a dictionary with three keys: 'LogisticRegression', 'SVM' and 'KNN'\n",
        "#assigns the values of test_accuracy, svmtest_accuracy, and testknn_accuracy to the variables acc_dict.\n",
        "acc_dict = {'LogisticRegression' : test_accuracy, 'SVM' : svmtest_accuracy, 'KNN' : testknn_accuracy}\n",
        "\n",
        "#printing the values \n",
        "acc_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oinu20Mg92S7"
      },
      "source": [
        "# **Summary**\n",
        "As we can see all our models have performed brilliantly after feature selection and is giving good out of sample accuracy. Hence, there is no need for Optimization/Hyperparameter Optimization, So we can state that our model is ready to be deployed. So this is how we can build a Breast cancer detection model using Machine Learning and the Python programming language. I hope you liked this project on how to build a breast cancer detection model with Machine Learning. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3oH6dgORtTZ"
      },
      "source": [
        "However, the best cross validation score was given by LogisticRegression & SVM model.\n",
        "So let's pickle and save our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgL6wblpQUtX"
      },
      "source": [
        "# Saving the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qd0fYezuGVph"
      },
      "outputs": [],
      "source": [
        "import pickle #keeps track of the objects it has already serialized ==> allows saving model in very little tym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "By3k8SopGsvZ"
      },
      "outputs": [],
      "source": [
        "#save the model trained in the file \"trained_model.sav\" to a new file called \"breastcancer_trained_model.pkl\"\n",
        "filename = 'breastcancer_trained_model.sav'\n",
        "pickle.dump(clf, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiC4pRThYaiq"
      },
      "outputs": [],
      "source": [
        "#loading the saved model\n",
        "loaded_model = pickle.load(open('breastcancer_trained_model.sav', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vglRC33YeCC",
        "outputId": "16cd4526-d6e7-4a5c-ef3a-121a0edef021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17.99, 10.38, 122.8, 1001, 0.1184, 0.2776, 0.3001, 0.1471, 0.2419, 0.07871, 1.095, 0.9053, 8.589, 153.4, 0.006399, 0.04904, 0.05373, 0.01587, 0.03003, 0.006193, 25.38, 17.33, 184.6, 2019, 0.1622, 0.6656, 0.7119, 0.2654, 0.4601, 0.1189)\n",
            "[0]\n",
            "Cancer is in Malignant stage\n"
          ]
        }
      ],
      "source": [
        "#v r predicting by giving the input \n",
        "input_data = (17.99,10.38,122.8,1001,0.1184,0.2776,0.3001,0.1471,0.2419,0.07871,1.095,0.9053,8.589,153.4,0.006399,0.04904,0.05373,0.01587,0.03003,0.006193,25.38,17.33,184.6,2019,0.1622,0.6656,0.7119,0.2654,0.4601,0.1189)\n",
        "#change input_data 2 numpy_array 2 make prediction\n",
        "input_data_as_numpy_array = np.asarray(input_data)\n",
        "print(input_data)\n",
        "\n",
        "#reshape the array as v r predicting the output for 1 instance \n",
        "input_data_reshaped = input_data_as_numpy_array.reshape(1, -1)\n",
        "\n",
        "#prediction\n",
        "prediction = loaded_model.predict(input_data_reshaped)\n",
        "print(prediction) #returns a list with element [0] if Malignant else [1] for Benign\n",
        "\n",
        "if (prediction[0] == 0):\n",
        "  print('Cancer is in Malignant stage')\n",
        "else:\n",
        "  print(\"Cancer is in Benign stage\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Breast Cancer Detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}